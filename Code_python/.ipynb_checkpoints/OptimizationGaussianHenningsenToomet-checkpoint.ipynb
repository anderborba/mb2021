{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with two parameters in Gaussian distribution\n",
    "\n",
    "The objective of this notebook is to understand how to estimate parameters with gaussian distribution using the scipy.optimize package. \n",
    "\n",
    "Hence, we assume the gaussian distributions, so the density is\n",
    "\\begin{equation}\n",
    "f_{Z}(z; \\mu, \\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\{-(z-\\mu)^2/2\\sigma^2\\}.\n",
    "\\tag{eq:01}\n",
    "\\end{equation}\n",
    "\n",
    "We illustrate the idea of finding parameters to the density applying  MLE (Maximum Likelihood Estimation). For this, we use log on both sides of the equation (eq:01),\n",
    "\\begin{equation}\n",
    "\\ell(z; \\mu, \\sigma)=\\log\\frac{1}{\\sigma} + \\log\\frac{1}{\\sqrt{2\\pi}} + \\log\\Bigg(\\exp\\{-(z-\\mu)^2/2\\sigma^2\\}\\Bigg),\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\ell(z; \\mu, \\sigma)=\\log\\sigma^{-1} + \\log\\sqrt{2\\pi}^{-1}-\\frac{1}{2\\sigma^2}(z-\\mu)^2,\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\ell(z; \\mu, \\sigma)=-\\log\\sigma - \\log\\sqrt{2\\pi}-\\frac{1}{2\\sigma^2}(z-\\mu)^2.\n",
    "\\tag{eq:02}\n",
    "\\end{equation}\n",
    "\n",
    "We used the equation (eq:02) intending to find the log-likelihood function\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= \\sum_{i=1}^n\\ell(z_i; \\mu, \\sigma),\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= \\sum_{i=1}^n\\Bigg[-\\log\\big(\\sigma\\big) - \\log\\big(\\sqrt{2\\pi}\\big)-\\frac{1}{2\\sigma^2}(z_i-\\mu)^2\\Bigg],\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= -\\sum_{i=1}^n\\log\\big(\\sigma\\big) - \\sum_{i=1}^n\\log\\big(\\sqrt{2\\pi}\\big)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n\\Bigg[\\frac{1}{2\\sigma^2}(z_i-\\mu)^2\\Bigg],\n",
    "\\end{equation}\n",
    "where, the algebraic manipulation results on the log-likelihood function with two parameters ($\\mu,\\sigma$),\n",
    "\\begin{equation}\n",
    "\\mathcal{L}(\\mu, \\sigma)= -n\\log\\big(\\sigma\\big) - n\\log\\big(\\sqrt{2\\pi}\\big)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(z_i-\\mu)^2.\n",
    "\\tag{eq:03}\n",
    "\\end{equation}\n",
    " \n",
    "The code below defines the sample with mean and standard deviation, respectively equal to 1 and 2. Additionally, the code sets the log-likelihood function (eq:03)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik(theta, x, N):\n",
    "    # AAB: Guarantee the parameters positivity.\n",
    "    mu = np.abs(theta[0])\n",
    "    sigma = np.abs(theta[1])\n",
    "    # AAB: Signal because we use the minimize. \n",
    "    l = -(-N * np.log(np.sqrt(2*np.pi)) - N*np.log(sigma) - 0.5*np.sum((x - mu)**2/sigma**2))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "mean = 1\n",
    "sd = 2\n",
    "z = np.random.normal(mean, sd, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply an optimization process using scipy.optimize package to find the parameters $\\mu$ and $\\sigma$. Some information are sumarized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = np.zeros(2)\n",
    "var[0] = 0.5\n",
    "var[1] = 0.5\n",
    "res = minimize(lambda varx:loglik(varx, z, n), var, method=\"BFGS\", \\\n",
    "                  tol = 1e-08, \\\n",
    "                  options={'gtol': 1e-08, \\\n",
    "                           'eps': 1.4901161193847656e-08,\\\n",
    "                           'maxiter': 200, \\\n",
    "                           'disp': True,   \\\n",
    "                           'return_all': True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  allvecs: [array([0.5, 0.5]), array([0.54767175, 1.50887433]), array([0.84637849, 1.49633678]), array([0.85828796, 1.59383583]), array([0.88868035, 1.8283159 ]), array([0.90340061, 1.97347311]), array([0.91096358, 2.06832841]), array([0.91261461, 2.10138272]), array([0.91246061, 2.10697347]), array([0.91225365, 2.10725011]), array([0.91212498, 2.10727021]), array([0.9120711 , 2.10725401]), array([0.91206935, 2.10724989]), array([0.9120696 , 2.10724955]), array([0.9120696 , 2.10724953])]\n",
      "      fun: 216.43220897163303\n",
      " hess_inv: array([[ 0.04046156, -0.00036604],\n",
      "       [-0.00036604,  0.01370223]])\n",
      "      jac: array([0.00000000e+00, 1.90734863e-06])\n",
      "  message: 'Desired error not necessarily achieved due to precision loss.'\n",
      "     nfev: 77\n",
      "      nit: 14\n",
      "     njev: 19\n",
      "   status: 2\n",
      "  success: False\n",
      "        x: array([0.9120696 , 2.10724953])\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
